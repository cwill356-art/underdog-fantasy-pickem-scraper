name: Esports-only props
on:
  workflow_dispatch: {}

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          pip install pandas requests beautifulsoup4 python-dateutil pytz

      # -----------------------------
      # 1) Run base scraper
      # -----------------------------
      - name: Run base scraper (writes underdog_props.csv)
        run: |
          python - << 'PY'
          from underdog_scraper import UnderdogScraper
          UnderdogScraper().scrape()
          PY

      # -----------------------------
      # 2) Filter to esports (LoL + CS2/CSGO + VALORANT + Dota2 + CoD)
      # -----------------------------
      - name: Filter to esports (LoL + CS2/CSGO + VALORANT + Dota2 + CoD)
        run: |
          python - << 'PY'
          import re, json
          import pandas as pd

          df = pd.read_csv("underdog_props.csv")

          def first_col_like(cols, names):
            cols = list(cols)
            for want in names:
              for c in cols:
                cl = c.lower()
                if cl == want or want in cl:
                  return c
            return None

          COL_FULL = first_col_like(df.columns, ["full_name","player","name"])
          COL_STAT = first_col_like(df.columns, ["stat_name","market","category","stat"])
          COL_LINE = first_col_like(df.columns, ["stat_value","line","value"])
          COL_SIDE = first_col_like(df.columns, ["choice","side"])
          COL_AMER = first_col_like(df.columns, ["american_price","americanodds","american_odds"])
          COL_DEC  = first_col_like(df.columns, ["decimal_price","decimalodds","decimal_odds"])
          COL_PAY  = first_col_like(df.columns, ["payout_multiplier","payout"])
          COL_HDR  = first_col_like(df.columns, ["selection_header","player_header","title","matchup"])
          COL_SUB  = first_col_like(df.columns, ["selection_subheader","league","subtitle","game"])
          COL_SID  = first_col_like(df.columns, ["sport_id","sportkey","sport_key"])
          COL_SNM  = first_col_like(df.columns, ["sport_name","sport"])
          COL_UPD  = first_col_like(df.columns, ["updated_at","last_updated","modified_at","scraped_at","timestamp"])

          ESPORT_ID_VALUES = {
            "LOL","LEAGUEOFLEGENDS","LEAGUE_OF_LEGENDS",
            "CS","CS2","CSGO","COUNTER_STRIKE","COUNTER-STRIKE",
            "VAL","VALORANT",
            "DOTA","DOTA2","DOTA_2",
            "COD","CALL_OF_DUTY","CALL-OF-DUTY"
          }

          NAME_KEYS = {
            "LOL": ["lol","league of legends","league-of-legends"],
            "CS" : ["cs2","cs:go","csgo","counter-strike","counter strike"],
            "VAL": ["val","valorant"],
            "DOTA":["dota2","dota 2","dota"],
            "COD":["call of duty","call-of-duty","cod"]
          }

          MARKET_KEYS = {
            "LOL": ["kills","assists","deaths","cs","creep score","fantasy"],
            "CS":  ["kills","headshots","hs","adr","kpr","deaths","fantasy"],
            "VAL": ["kills","headshots","first blood","fb","plants","defuses","assists","deaths","fantasy","clutches"],
            "DOTA":["kills","assists","deaths","last hits","lh","denies","gpm","xpm","fantasy"],
            "COD": ["kills","deaths","assists","kda","damage","fantasy"]
          }

          def infer_title(row):
            if COL_SID:
              sid = str(row.get(COL_SID,"")).strip().upper()
              if sid in ESPORT_ID_VALUES:
                if "LOL" in sid or "LEAGUE" in sid: return "LOL"
                if "CS"  in sid or "COUNTER" in sid: return "CS"
                if "VAL" in sid: return "VAL"
                if "DOTA" in sid: return "DOTA"
                if "COD" in sid or "CALL" in sid: return "COD"
            hay = " ".join([str(row.get(COL_SNM,"")),
                            str(row.get(COL_HDR,"")),
                            str(row.get(COL_SUB,"")),
                            str(row.get(COL_STAT,""))]).lower()
            for title, keys in NAME_KEYS.items():
              if any(k in hay for k in keys):
                return title
            return ""

          def is_target_esport_row(row):
            title = infer_title(row)
            if not title:
              return False
            stat = str(row.get(COL_STAT,"")).lower()
            hay = " ".join([stat, str(row.get(COL_SUB,"")).lower(), str(row.get(COL_HDR,"")).lower()])
            keys = MARKET_KEYS.get(title, [])
            return any(k in hay for k in keys)

          def norm_player(row):
            name = str(row.get(COL_FULL,"")).strip() if COL_FULL else ""
            if name and name.lower() != "nan":
              return name
            alt = str(row.get(COL_HDR,"")).strip() if COL_HDR else ""
            return alt

          if len(df)==0:
            out = df.iloc[0:0].copy()
          else:
            mask = df.apply(is_target_esport_row, axis=1)
            out = df[mask].copy()

          if out.empty:
            out = pd.DataFrame(columns=[
              "title","player","market","line","side","american_price","decimal_price",
              "payout_multiplier","sport_name","sport_id","selection_header",
              "selection_subheader","updated_at"
            ])
          else:
            out["title"] = out.apply(infer_title, axis=1)
            out["player"] = out.apply(norm_player, axis=1)
            out = out.assign(
              market     = out[COL_STAT] if COL_STAT in out.columns else "",
              line       = out[COL_LINE] if COL_LINE in out.columns else "",
              side       = out[COL_SIDE] if COL_SIDE in out.columns else "",
              american_price = out[COL_AMER] if COL_AMER in out.columns else "",
              decimal_price  = out[COL_DEC] if COL_DEC in out.columns else "",
              payout_multiplier = out[COL_PAY] if COL_PAY in out.columns else "",
              sport_name = out[COL_SNM] if COL_SNM in out.columns else "",
              sport_id   = out[COL_SID] if COL_SID in out.columns else "",
              selection_header = out[COL_HDR] if COL_HDR in out.columns else "",
              selection_subheader = out[COL_SUB] if COL_SUB in out.columns else "",
              updated_at = out[COL_UPD] if COL_UPD in out.columns else ""
            )[[
              "title","player","market","line","side","american_price","decimal_price",
              "payout_multiplier","sport_name","sport_id","selection_header",
              "selection_subheader","updated_at"
            ]]

          out.to_csv("underdog_props_esports.csv", index=False)
          print(json.dumps(out.head(60).to_dict(orient="records"), ensure_ascii=False, indent=2))
          print("ROWS:", len(out))
          PY

      - name: Upload esports-only CSV
        uses: actions/upload-artifact@v4
        with:
          name: underdog_props_esports
          path: underdog_props_esports.csv

      # -----------------------------
      # 3) Add the Schedule Resolver module
      # -----------------------------
      - name: Write schedule_resolver.py
        run: |
          cat > schedule_resolver.py << 'PY'
          import re
          from datetime import datetime, timezone
          from typing import List, Dict, Optional, Tuple
          import requests
          from bs4 import BeautifulSoup
          from dateutil import parser as dtp
          import pytz

          TZ_CHICAGO = pytz.timezone("America/Chicago")

          def _norm(s: str) -> str:
            return re.sub(r"\s+", " ", (s or "").strip().lower())

          def _safe_parse_dt(s: str) -> Optional[datetime]:
            try:
              dt = dtp.parse(s)
              if not dt.tzinfo:
                dt = dt.replace(tzinfo=timezone.utc)
              return dt.astimezone(timezone.utc)
            except Exception:
              return None

          def _now_utc() -> datetime:
            return datetime.now(timezone.utc)

          # ------------ VALORANT (VLR.gg) ------------
          def fetch_valorant_schedule() -> List[Dict]:
            url = "https://www.vlr.gg/matches"
            r = requests.get(url, timeout=25, headers={"User-Agent":"Mozilla/5.0"})
            r.raise_for_status()
            soup = BeautifulSoup(r.text, "html.parser")
            out = []
            for row in soup.select(".wf-module-item.match-item"):
              teams = row.select(".match-item-vs-team-name")
              if len(teams) != 2:
                continue
              t1 = _norm(teams[0].get_text())
              t2 = _norm(teams[1].get_text())
              start_utc = None
              ts_el = row.select_one(".moment-tz-convert")
              if ts_el and ts_el.has_attr("data-utc-ts"):
                try:
                  ts = int(ts_el["data-utc-ts"])
                  start_utc = datetime.fromtimestamp(ts, tz=timezone.utc)
                except Exception:
                  pass
              if not start_utc:
                tt = row.select_one(".match-item-time")
                if tt:
                  start_utc = _safe_parse_dt(tt.get_text())
              out.append({"title":"VAL","team1":t1,"team2":t2,"start_utc":start_utc})
            return out

          # ------------ CS2 (HLTV) ------------
          def fetch_cs2_schedule() -> List[Dict]:
            url = "https://www.hltv.org/matches"
            r = requests.get(url, timeout=25, headers={"User-Agent":"Mozilla/5.0"})
            r.raise_for_status()
            soup = BeautifulSoup(r.text, "html.parser")
            out = []
            for m in soup.select(".upcomingMatch, .match-day"):
              names = [t.get_text() for t in m.select(".matchTeamName")]
              if len(names) >= 2:
                t1, t2 = _norm(names[0]), _norm(names[1])
              else:
                continue
              ts = None
              holder = m.select_one("[data-unix]")
              if holder and holder.has_attr("data-unix"):
                try:
                  ts = int(holder["data-unix"]) // 1000
                except Exception:
                  ts = None
              start_utc = datetime.fromtimestamp(ts, tz=timezone.utc) if ts else None
              out.append({"title":"CS2","team1":t1,"team2":t2,"start_utc":start_utc})
            return out

          # ------------ LoL (gol.gg) ------------
          def fetch_lol_schedule() -> List[Dict]:
            url = "https://gol.gg/tournament/tournament-matchlist/0/"
            r = requests.get(url, timeout=25, headers={"User-Agent":"Mozilla/5.0"})
            r.raise_for_status()
            soup = BeautifulSoup(r.text, "html.parser")
            out = []
            for row in soup.select("table.table tbody tr"):
              cols = row.select("td")
              if len(cols) < 4: 
                continue
              t1 = _norm(cols[1].get_text())
              t2 = _norm(cols[3].get_text())
              tstr = cols[0].get_text()
              start_utc = _safe_parse_dt(tstr)
              out.append({"title":"LOL","team1":t1,"team2":t2,"start_utc":start_utc})
            return out

          def build_schedule_index() -> List[Dict]:
            sched = []
            try: sched += fetch_valorant_schedule()
            except Exception: pass
            try: sched += fetch_cs2_schedule()
            except Exception: pass
            try: sched += fetch_lol_schedule()
            except Exception: pass
            sched = [s for s in sched if s.get("start_utc")]
            return sched

          def _teams_from_subheader(sub: str) -> Tuple[str,str]:
            s = _norm(sub)
            if " vs " in s:
              left,right = s.split(" vs ",1)
            elif " v " in s:
              left,right = s.split(" v ",1)
            elif "@" in s:
              left,right = s.split("@",1)
            else:
              parts = re.split(r"[-–—]", s, maxsplit=1)
              if len(parts)==2:
                left,right = parts[0], parts[1]
              else:
                left,right = s,""
            left = re.sub(r"(maps?.*)","",left).strip()
            right = re.sub(r"(maps?.*)","",right).strip()
            return left, right

          def attach_match_times(rows: List[Dict]) -> List[Dict]:
            schedule = build_schedule_index()
            out = []
            now = _now_utc()
            for r in rows:
              sub = r.get("selection_subheader") or ""
              t1, t2 = _teams_from_subheader(sub)
              start = None
              for s in schedule:
                if not s.get("start_utc"): 
                  continue
                st1, st2 = s["team1"], s["team2"]
                if ((t1 and (t1 in st1 or st1 in t1)) and (t2 and (t2 in st2 or st2 in t2))) or \
                   ((t1 and (t1 in st2 or st2 in t1)) and (t2 and (t2 in st1 or st1 in t2))):
                  start = s["start_utc"]; break
              has_started_utc = (start is not None and now >= start)
              start_ct = start.astimezone(TZ_CHICAGO) if start else None
              has_started_ct = (start_ct is not None and datetime.now(TZ_CHICAGO) >= start_ct)
              r2 = dict(r)
              r2["match_start_utc"] = start.isoformat() if start else ""
              r2["match_start_ct"] = start_ct.isoformat() if start_ct else ""
              r2["has_started_utc"] = has_started_utc
              r2["has_started_ct"]  = has_started_ct
              r2["not_started_ct"]  = not has_started_ct
              out.append(r2)
            return out
          PY

      # -----------------------------
      # 4) Enrich esports file with match times + filter not-started
      # -----------------------------
      - name: Enrich with schedules (HLTV / VLR / gol.gg)
        run: |
          python - << 'PY'
          import pandas as pd
          from schedule_resolver import attach_match_times

          SRC = "underdog_props_esports.csv"
          ENR = "underdog_props_esports_enriched.csv"
          NST = "underdog_props_esports_not_started.csv"

          df = pd.read_csv(SRC)
          rows = df.to_dict(orient="records")
          enriched = attach_match_times(rows)
          out = pd.DataFrame(enriched)
          out.to_csv(ENR, index=False)
          out[out["not_started_ct"]==True].to_csv(NST, index=False)
          print(f"Enriched rows: {len(out)}")
          print(f"Not-started rows: {len(out[out['not_started_ct']==True])}")
          PY

      # -----------------------------
      # 5) Upload artifacts
      # -----------------------------
      - name: Upload enriched CSV
        uses: actions/upload-artifact@v4
        with:
          name: underdog_props_esports_enriched
          path: underdog_props_esports_enriched.csv

      - name: Upload not-started CSV
        uses: actions/upload-artifact@v4
        with:
          name: underdog_props_esports_not_started
          path: underdog_props_esports_not_started.csv
