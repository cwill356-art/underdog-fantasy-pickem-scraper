name: HLTV projections from Underdog props
on:
  workflow_dispatch:
    inputs:
      ud_artifact_name:
        description: "Name of the Underdog artifact to pull"
        required: false
        default: "underdog_props_esports"
      lookback_days:
        description: "HLTV player stats lookback window (days)"
        required: false
        default: "60"
      throttle_ms:
        description: "Delay between HLTV requests (ms)"
        required: false
        default: "350"

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install deps
        run: npm i hltv papaparse

      - name: Download latest Underdog artifact (CSV) by name
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ART_NAME: ${{ inputs.ud_artifact_name }}
          REPO: ${{ github.repository }}
        run: |
          set -e
          echo "Finding latest artifact named: $ART_NAME"
          curl -sS -H "Authorization: Bearer $GH_TOKEN" \
            "https://api.github.com/repos/$REPO/actions/artifacts?per_page=100" > artifacts.json

          ART_ID=$(jq -r --arg NAME "$ART_NAME" '.artifacts | map(select(.name==$NAME and .expired==false)) | sort_by(.created_at) | last | .id // empty' artifacts.json)

          if [ -z "$ART_ID" ] || [ "$ART_ID" = "null" ]; then
            echo "No active artifact named '$ART_NAME' found. Creating empty placeholder."
            mkdir -p ud_artifact && touch ud_artifact/underdog_props_esports.csv
          else
            echo "Downloading artifact id: $ART_ID"
            curl -sSL -H "Authorization: Bearer $GH_TOKEN" \
              -H "Accept: application/octet-stream" \
              "https://api.github.com/repos/$REPO/actions/artifacts/$ART_ID/zip" -o ud_artifact.zip
            mkdir -p ud_artifact
            unzip -o ud_artifact.zip -d ud_artifact >/dev/null
          fi

          echo "Artifacts in ud_artifact:"
          ls -la ud_artifact || true

      - name: Build projections from UD players and join edges
        env:
          LOOKBACK_DAYS: ${{ inputs.lookback_days }}
          THROTTLE_MS: ${{ inputs.throttle_ms }}
        run: |
          node - <<'JS'
          // ---------------- Imports ----------------
          const { HLTV } = require('hltv');     // official Node wrapper
          const fs = require('fs');
          const Papa = require('papaparse');

          // Node 20 has global fetch
          const sleep = (ms)=>new Promise(r=>setTimeout(r,ms));

          // --------------- Helpers -----------------
          const writeCSV = (rows, path) => {
            try {
              const csv = Papa.unparse(rows || [], { quotes: true });
              fs.writeFileSync(path, csv);
            } catch (e) {
              console.error('writeCSV error for', path, e?.message);
              try { fs.writeFileSync(path, ''); } catch {}
            }
          };
          const readCSVauto = (path) => {
            try {
              const txt = fs.readFileSync(path, 'utf8');
              const parsed = Papa.parse(txt, { header: true });
              return parsed.data || [];
            } catch {
              return [];
            }
          };
          const impliedProb = (dec) => (isFinite(dec) && dec>0 ? 1/dec : 0.526); // default â‰ˆ 1.90
          const shrink = (rate, n, base, k) => ((n*rate + k*base) / ((n+k)||1));
          const leagueKPR = 0.68, leagueHS = 0.46;
          const EXPECTED_ROUNDS = 50; // balanced Maps 1+2 baseline (MR12)

          const LOOKBACK_DAYS = parseInt(process.env.LOOKBACK_DAYS||'60',10);
          const THROTTLE_MS   = parseInt(process.env.THROTTLE_MS  ||'350',10);

          const today = new Date();
          const startDate = new Date(today.getTime() - LOOKBACK_DAYS*24*3600*1000).toISOString().slice(0,10);
          const endDate   = today.toISOString().slice(0,10);

          // --------------- 1) Load UD CSV ----------------
          // Find the first CSV in ud_artifact/ that looks like UD props
          const udFiles = fs.existsSync('ud_artifact') ? fs.readdirSync('ud_artifact') : [];
          const udPath = udFiles.find(f => f.toLowerCase().endsWith('.csv')) ? ('ud_artifact/' + udFiles.find(f => f.toLowerCase().endsWith('.csv'))) : 'ud_artifact/underdog_props_esports.csv';
          const ud = readCSVauto(udPath);
          console.log('UD rows found:', ud.length, 'from', udPath);

          // Column helpers
          const pickCol = (row, keys) => {
            for (const k of keys) if (row.hasOwnProperty(k) && row[k] != null && row[k] !== '') return row[k];
            return '';
          };

          // Extract player names, markets, and odds
          const udClean = ud.map(r => {
            const player = String(pickCol(r, ['player','full_name','name','selection_header'])).trim();
            const market = String(pickCol(r, ['market','stat_name','category'])).trim();
            let line = pickCol(r, ['line','stat_value','value']);
            if (line === '' || line == null) {
              const ss = String(pickCol(r, ['selection_subheader','display'])).toLowerCase();
              const m = /(\d+(?:\.\d+)?)/.exec(ss);
              line = m ? m[1] : '';
            }
            const side = String(pickCol(r, ['side','choice'])).toLowerCase();
            const dec  = parseFloat(pickCol(r, ['decimal_price','decimalodds','decimal_odds']));
            const us   = pickCol(r, ['american_price','americanodds','american_odds']);
            return { player, market, line: line!==''?parseFloat(line):NaN, side, dec_odds: isFinite(dec)?dec:1.90, us_odds: us };
          }).filter(x => x.player && x.market);

          const playerNames = [...new Set(udClean.map(x => x.player.toLowerCase()))];
          console.log('Unique UD player names:', playerNames.length);

          // --------------- 2) Map names -> HLTV IDs via hosted directory ----------------
          // Pull a broad players list and do exact/loose matching.
          let playersDir = [];
          try {
            const res = await fetch('https://hltv-api.vercel.app/api/players', { headers: { 'user-agent': 'github-action-hltv-from-ud' }});
            playersDir = await res.json();
          } catch (e) {
            console.error('Hosted /players fetch failed:', e?.message);
          }
          // normalize helper
          const norm = s => String(s||'').toLowerCase().replace(/\s+/g,'').replace(/[^a-z0-9_]/g,'');
          const byNick = new Map();
          for (const p of (playersDir||[])) {
            const key = norm(p.nickname || p.name || '');
            if (key) byNick.set(key, p);
          }

          const mapped = [];
          for (const nm of playerNames) {
            const key = norm(nm);
            let m = byNick.get(key);
            if (!m && byNick.get(nm)) m = byNick.get(nm);
            if (m) {
              mapped.push({ ud_name: nm, hltv_id: m.id || m.playerId || m._id, nickname: m.nickname || m.name || nm });
            } else {
              mapped.push({ ud_name: nm, hltv_id: null, nickname: null });
            }
          }
          writeCSV(mapped, 'hl_players_mapped.csv');
          const withIDs = mapped.filter(x => x.hltv_id);

          console.log('Mapped to HLTV IDs:', withIDs.length, '/', mapped.length);

          // --------------- 3) Pull HLTV player stats for mapped IDs ----------------
          const stats = [];
          for (const m of withIDs) {
            try {
              const s = await HLTV.getPlayerStats({ id: m.hltv_id, startDate, endDate });
              stats.push({
                playerId: m.hltv_id,
                nickname: s?.player?.nickname || m.nickname || m.ud_name,
                team:     s?.team?.name || '',
                maps:     s?.overview?.mapsPlayed,
                kpr:      s?.overview?.kpr,
                hsPct:    s?.overview?.hsPercentage,
                adr:      s?.overview?.adr,
                rating:   s?.overview?.rating1
              });
            } catch (e) {
              console.error('getPlayerStats fail', m.hltv_id, m.ud_name, e?.message);
            }
            await sleep(parseInt(THROTTLE_MS,10));
          }
          writeCSV(stats, 'hltv_player_form.csv');

          // --------------- 4) Build conservative projections ----------------
          const pf = new Map(stats.map(r => [String(r.nickname||'').toLowerCase(), r]));
          const projRows = [];
          for (const r of stats) {
            const maps = +r.maps || 0;
            const kpr  = +r.kpr  || leagueKPR;
            const hs   = +r.hsPct || leagueHS;
            const kprAdj = shrink(kpr, maps, leagueKPR, maps < 25 ? 40 : 25);
            const hsAdj  = shrink(hs,  maps, leagueHS,  maps < 25 ? 60 : 40);
            const muKills = EXPECTED_ROUNDS * kprAdj;
            projRows.push({
              player: r.nickname, team: r.team, maps,
              kprAdj: +kprAdj.toFixed(3), hsAdj: +hsAdj.toFixed(3),
              projKills: +muKills.toFixed(1), projHS: +(muKills*hsAdj).toFixed(1)
            });
          }
          writeCSV(projRows, 'hltv_projections.csv');

          // --------------- 5) Join vs UD props + probabilities/edges ---------------
          function tailProbOver(line, mu, variance) {
            const sigma = Math.sqrt(Math.max(variance, 1e-6));
            const z = (line - mu)/sigma;
            const cdf = (x)=>0.5*(1+Math.erf(x/Math.SQRT2));
            const pOver = 1 - cdf(z);
            return { pOver, pUnder: 1 - pOver, sigma };
          }

          const outEdges = [];
          for (const u of udClean) {
            const nickname = u.player.toLowerCase();
            const form = pf.get(nickname);
            if (!form || !isFinite(u.line)) continue;

            const maps = +form.maps || 0;
            const kpr  = +form.kpr  || leagueKPR;
            const hs   = +form.hsPct || leagueHS;
            const kprAdj = shrink(kpr, maps, leagueKPR, maps < 25 ? 40 : 25);
            const hsAdj  = shrink(hs,  maps, leagueHS,  maps < 25 ? 60 : 40);
            const muKills = EXPECTED_ROUNDS * kprAdj;

            let mu, variance;
            const mkt = u.market.toLowerCase();
            if (mkt.includes('kills_on_maps_1_2')) {
              mu = muKills;
              variance = EXPECTED_ROUNDS * kprAdj * (1 - kprAdj) + 3.0; // cushion
            } else if (mkt.includes('headshots_on_maps_1_2')) {
              mu = muKills * hsAdj;
              variance = muKills * hsAdj * (1 - hsAdj) + 2.0;          // cushion
            } else {
              continue; // ignore non-CS2 markets here
            }

            const { pOver, pUnder, sigma } = tailProbOver(u.line, mu, variance);
            const modelProb = u.side === 'over' ? pOver : pUnder;
            const implied = impliedProb(u.dec_odds);
            const edge = modelProb - implied;

            outEdges.push({
              player: u.player,
              team: form.team || '',
              market: u.market,
              side: u.side,
              ud_line: +u.line.toFixed(1),
              ud_dec: +u.dec_odds,
              our_mu: +mu.toFixed(2),
              our_sigma: +sigma.toFixed(2),
              prob_over: +pOver.toFixed(3),
              prob_under: +pUnder.toFixed(3),
              model_prob: +modelProb.toFixed(3),
              edge: +edge.toFixed(3),
              sample_maps: form.maps
            });
          }

          // Sort best edges first
          outEdges.sort((a,b)=> b.edge - a.edge);
          writeCSV(outEdges, 'ud_vs_model_edges.csv');

          console.log(`Done. UD rows: ${udClean.length}, mapped IDs: ${withIDs.length}, HLTV stats rows: ${stats.length}, edges: ${outEdges.length}`);
          JS

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: hltv_from_ud_edges
          path: |
            artifacts.json
            ud_artifact.zip
            ud_artifact/**
            hl_players_mapped.csv
            hltv_player_form.csv
            hltv_projections.csv
            ud_vs_model_edges.csv
          if-no-files-found: warn
