name: NFL props (Underdog) — exhaustive

on:
  workflow_dispatch: {}

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          pip install requests pandas tenacity python-dateutil

      - name: Scrape ALL NFL props from Underdog (writes underdog_nfl_props.csv)
        run: |
          python - << 'PY'
          import json, math, time, re, sys
          from datetime import datetime, timezone
          from dateutil import parser as dtp
          import pandas as pd
          import requests
          from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

          # ------------------------- config -------------------------
          UA = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
          BASES = [
              "https://api.underdogfantasy.com/beta/v3",  # primary (web app uses these)
              "https://api.underdogfantasy.com/v1"        # fallback (some installs still mirror here)
          ]
          # Some sites expose both "over_under_lines" and "offers" style feeds depending on rollout.
          ROUTES = [
              # each tuple: (route, supports_cursor)
              ("over_under_lines", True),   # typical: ?limit=100&cursor=
              ("offers", True),             # typical: ?limit=100&cursor=
              ("over_under_lines_v2", True) # sometimes present in beta
          ]

          # “NFL-ness” signals we accept (id/name/group strings vary by rollout)
          NFL_KEYS = {
              "nfl", "national football league", "football-nfl", "pro football"
          }

          # Markets we consider “NFL props”
          NFL_MARKET_HINTS = [
              # QB
              "passing yards","pass yards","pass attempts","passing attempts","pass completions",
              "completions","interceptions","ints","passing tds","pass tds",
              # RB
              "rushing yards","rush yards","rushing attempts","longest rush","rush tds",
              # WR/TE
              "receiving yards","receptions","longest reception","rec tds",
              # K
              "field goals made","fg made","kicking points","extra points made",
              # Defense / misc that sometimes appear
              "fantasy points","fantasy score","tackles","tackles + assists","tfl","sacks"
          ]

          SESSION = requests.Session()
          SESSION.headers.update({"User-Agent": UA, "Accept": "application/json"})

          class SoftFail(Exception): ...
          def _is_json(r):
              return "application/json" in r.headers.get("content-type","").lower()

          @retry(reraise=True,
                 retry=retry_if_exception_type((requests.RequestException, SoftFail)),
                 wait=wait_exponential(multiplier=0.8, min=1, max=8),
                 stop=stop_after_attempt(5))
          def get_json(url, params=None):
              r = SESSION.get(url, params=params, timeout=20)
              if r.status_code >= 500:
                  raise SoftFail(f"Server {r.status_code}")
              if r.status_code == 429:
                  # basic backoff on rate-limit
                  raise SoftFail("429 rate limited")
              r.raise_for_status()
              if not _is_json(r):
                  raise SoftFail("Not JSON response")
              return r.json()

          def textish(x):
              return (x or "").strip() if isinstance(x, str) else ""

          def looks_nfl_bucket(s: str) -> bool:
              s = textish(s).lower()
              return any(k in s for k in NFL_KEYS)

          def looks_nfl_market(s: str) -> bool:
              s = textish(s).lower()
              return any(k in s for k in NFL_MARKET_HINTS)

          def normalize_side(raw: str):
              s = textish(raw).lower()
              if s in ("higher","over"): return "Over"
              if s in ("lower","under"): return "Under"
              return s.title() if s else ""

          # Grab everything from a base/route pair (cursor pagination if supported).
          def harvest(base, route, supports_cursor=True, limit=200):
              url = f"{base}/{route}"
              cursor = None
              page = 0
              while True:
                  params = {"limit": limit}
                  if supports_cursor and cursor:
                      params["cursor"] = cursor
                  try:
                      data = get_json(url, params=params)
                  except Exception as e:
                      # stop on hard failure of this route; other routes/bases will still run
                      break
                  # Heuristic: many Underdog JSONs embed array under 'over_under_lines' or 'offers' or 'data'
                  items = (data.get("over_under_lines")
                           or data.get("offers")
                           or data.get("data")
                           or data.get("items")
                           or [])
                  if not isinstance(items, list):
                      # try nested common envelope:
                      items = (data.get("payload", {}).get("items") or [])
                  yield from items

                  # cursor styles differ: sometimes 'next_cursor', sometimes 'links' etc.
                  cursor = data.get("next_cursor") or data.get("meta", {}).get("next_cursor")
                  page += 1
                  if not supports_cursor:
                      break
                  if not cursor:
                      break

          def safe_get(obj, *path):
              for p in path:
                  if isinstance(obj, dict) and p in obj:
                      obj = obj[p]
                  else:
                      return None
              return obj

          rows = []

          # --------------- crawl ---------------
          for base in BASES:
              for route, supports_cursor in ROUTES:
                  try:
                      for it in harvest(base, route, supports_cursor=supports_cursor):
                          # Different deployments place essentials in slightly different places.
                          # We probe multiple “shapes” and accept the first that fits.
                          #
                          # Common fields:
                          # - player: obj["appearance"]["player"]["name"] OR obj["player"]["full_name"]
                          # - sport/league/group: obj["appearance"]["sport"]["name"] / ["league"]["name"] / ["group"]
                          # - market name: obj["over_under"]["stat"] OR obj["market"]["name"]
                          # - line: obj["line"] OR obj["over_under"]["line"]
                          # - side: obj["choice"] OR obj["pick"]["type"]
                          # - team/game text often found in headers/subheaders
                          #
                          # ------------- extract -------------
                          appearance = safe_get(it, "appearance") or {}
                          player_obj = safe_get(appearance, "player") or safe_get(it, "player") or {}
                          sport_obj  = safe_get(appearance, "sport") or safe_get(it, "sport") or {}
                          league_obj = safe_get(appearance, "league") or safe_get(it, "league") or {}
                          group      = textish(safe_get(it, "group") or safe_get(league_obj, "group") or "")

                          sport_name = textish(safe_get(sport_obj, "name") or safe_get(it, "sport_name") or "")
                          league_name = textish(safe_get(league_obj, "name") or safe_get(it, "league_name") or "")
                          # early NFL filter (cheap)
                          bucket_text = " ".join([sport_name, league_name, group])
                          if not looks_nfl_bucket(bucket_text):
                              # some payloads omit names; try stat-market sniffing below
                              pass

                          player_name = textish(safe_get(player_obj, "name") or safe_get(player_obj, "full_name") or safe_get(it, "player_name") or "")
                          market = textish(safe_get(it, "market", "name")
                                           or safe_get(it, "over_under", "stat")
                                           or safe_get(it, "stat_type")
                                           or safe_get(it, "stat_name")
                                           or safe_get(it, "category"))
                          line = safe_get(it, "line") or safe_get(it, "over_under", "line") or safe_get(it, "value") or safe_get(it, "stat_value")
                          side_raw = textish(safe_get(it, "choice") or safe_get(it, "pick", "type") or safe_get(it, "side"))
                          side = normalize_side(side_raw)

                          # helpful cosmetic fields
                          header = textish(safe_get(it, "selection_header") or safe_get(it, "title") or safe_get(it, "player_header"))
                          sub    = textish(safe_get(it, "selection_subheader") or safe_get(it, "subtitle") or safe_get(it, "matchup"))
                          updated_at = safe_get(it, "updated_at") or safe_get(it, "modified_at") or safe_get(it, "created_at")
                          if isinstance(updated_at, (int, float)):
                              # treat as epoch seconds if it looks like it
                              try:
                                  updated_at = datetime.fromtimestamp(updated_at, tz=timezone.utc).isoformat()
                              except Exception:
                                  updated_at = ""

                          # Reject obviously broken items
                          if not player_name or not market:
                              continue

                          # NFL acceptance: bucket OR market looks like NFL prop
                          if not looks_nfl_bucket(bucket_text) and not looks_nfl_market(market):
                              continue

                          # force float line when possible
                          try:
                              line_num = float(line)
                          except Exception:
                              # Sometimes “Yes/No” type markets — keep them if they’re NFL and useful
                              line_num = None

                          rows.append({
                              "player": player_name,
                              "sport_name": sport_name or "NFL",
                              "league_name": league_name,
                              "market": market,
                              "line": line_num if line_num is not None else textish(line),
                              "side": side,
                              "selection_header": header,
                              "selection_subheader": sub,
                              "updated_at": updated_at,
                              # Keep raw for debugging/version drift
                              "_route": route,
                              "_base": base
                          })
                  except Exception:
                      # If a route explodes, carry on to others
                      continue

          # --------------- tidy & de-dupe ---------------
          df = pd.DataFrame(rows)
          if df.empty:
              # keep schema even if nothing returned
              df = pd.DataFrame(columns=[
                  "player","sport_name","league_name","market","line","side",
                  "selection_header","selection_subheader","updated_at","_route","_base"
              ])

          # strict nfl filter pass based on market string as a last gate
          nfl_df = df[df["market"].str.lower().apply(looks_nfl_market)]
          # normalize market labels a bit
          def norm_market(s):
              s = s.lower()
              s = s.replace("pass ", "passing ").replace("rush ", "rushing ")
              s = s.replace(" rec ", " receiving ")
              return " ".join(s.split())
          if not nfl_df.empty:
              nfl_df["market"] = nfl_df["market"].apply(norm_market)

          # de-dupe by same (player, market, line, side) preferring the newest updated_at
          def parse_dt(x):
              try:
                  return dtp.parse(str(x))
              except Exception:
                  return datetime.min.replace(tzinfo=timezone.utc)
          if not nfl_df.empty:
              nfl_df["_ts"] = nfl_df["updated_at"].apply(parse_dt)
              nfl_df = (
                  nfl_df.sort_values("_ts", ascending=False)
                        .drop_duplicates(subset=["player","market","line","side"], keep="first")
                        .drop(columns=["_ts"])
              )

          # final ordering
          cols = ["player","sport_name","league_name","market","line","side",
                  "selection_header","selection_subheader","updated_at","_route","_base"]
          for c in cols:
              if c not in nfl_df.columns: nfl_df[c] = ""
          nfl_df = nfl_df[cols].reset_index(drop=True)

          nfl_df.to_csv("underdog_nfl_props.csv", index=False)
          print("ROWS:", len(nfl_df))
          print(json.dumps(nfl_df.head(40).to_dict(orient="records"), ensure_ascii=False, indent=2))
          PY

      - name: Upload NFL CSV
        uses: actions/upload-artifact@v4
        with:
          name: underdog_nfl_props
          path: underdog_nfl_props.csv
