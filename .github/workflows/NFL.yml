name: NFL props (Underdog) — robust harvest

on:
  workflow_dispatch: {}
  # Optional schedule (uncomment to run every 15 min)
  # schedule:
  #   - cron: "*/15 * * * *"

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          pip install -q --upgrade pip
          pip install -q requests pandas tenacity python-dateutil beautifulsoup4

      - name: Scrape raw NFL payloads from Underdog
        run: |
          python - << 'PY'
          import os, json
          from datetime import datetime, timezone
          import requests
          from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type

          RAW_DIR = "raw_payloads"
          os.makedirs(RAW_DIR, exist_ok=True)

          UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"
          HDRS = {
            "User-Agent": UA,
            "Accept": "application/json,text/html;q=0.9,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9",
            "Referer": "https://underdogfantasy.com/pick-em/higher-lower/nfl",
            "Origin": "https://underdogfantasy.com",
            "Connection": "keep-alive",
          }

          S = requests.Session()
          S.headers.update(HDRS)

          class SoftFail(Exception): ...

          @retry(reraise=True,
                 retry=retry_if_exception_type((requests.RequestException, SoftFail)),
                 wait=wait_exponential(multiplier=1, min=1, max=8),
                 stop=stop_after_attempt(5))
          def get(url, params=None, expect_json=True):
              r = S.get(url, params=params, timeout=20)
              if r.status_code in (429,) or r.status_code >= 500:
                  raise SoftFail(f"{r.status_code}")
              r.raise_for_status()
              if expect_json:
                  try:
                      return r.json(), r
                  except Exception:
                      raise SoftFail("not json")
              return r.text, r

          def save_raw(name: str, content: str|bytes):
              mode = "wb" if isinstance(content, (bytes,bytearray)) else "w"
              with open(os.path.join(RAW_DIR, name), mode) as f:
                  f.write(content)

          # Multiple bases/routes to withstand rollout differences
          BASES = [
            "https://api.underdogfantasy.com/beta/v3",
            "https://sports.underdogfantasy.com/beta/v3",
            "https://api.underdogfantasy.com/v1"
          ]
          ROUTES = [
            ("over_under_lines", True),
            ("over_under_lines_v2", True),
            ("offers", True),
          ]

          hits = []

          # JSON routes with cursor-style pagination
          for base in BASES:
              for route, use_cursor in ROUTES:
                  url = f"{base}/{route}"
                  cursor = None
                  total = 0
                  page = 0
                  while True:
                      params = {"limit": 200}
                      if use_cursor and cursor:
                          params["cursor"] = cursor
                      try:
                          data, resp = get(url, params=params, expect_json=True)
                          save_raw(f"raw_{route}_{page}.json", resp.text.encode("utf-8"))
                          total += (len(data.get("over_under_lines", [])) +
                                    len(data.get("offers", [])) +
                                    (len(data.get("data", [])) if isinstance(data.get("data"), list) else 0) +
                                    len(data.get("items", [])))
                          cursor = data.get("next_cursor") or data.get("meta",{}).get("next_cursor")
                          page += 1
                          if not use_cursor or not cursor:
                              break
                      except Exception as e:
                          break
                  hits.append((url, total))

          # HTML fallback (__NEXT_DATA__)
          HTML_URLS = [
            "https://underdogfantasy.com/pick-em/higher-lower/nfl",
            "https://www.underdogfantasy.com/pick-em/higher-lower/nfl",
          ]
          for u in HTML_URLS:
              try:
                  html, resp = get(u, expect_json=False)
                  save_raw("raw_nfl_board.html", html.encode("utf-8"))
              except Exception:
                  pass

          print("SOURCES & COUNTS:")
          for (u,c) in hits:
              print(f"{c:5d}  {u}")
          PY

      - name: Normalize NFL props from raw payloads → underdog_nfl_props.csv
        run: |
          python - << 'PY'
          import os, re, json, glob
          import pandas as pd

          RAW_DIR = "raw_payloads"
          OUT_CSV = "underdog_nfl_props.csv"

          # ---------- helpers ----------
          def as_str(x):
              return (x if isinstance(x, str) else ("" if x is None else str(x))).strip()

          NFL_STAT_HINTS = [
              "rush", "rushing",
              "pass", "passing", "completions", "attempts", "interception",
              "receiv", "reception",
              "longest reception", "longest rush",
              "touchdown", "td",
              "fantasy",
              "tackle", "tackles", "assists", "sacks",
              "field goal", "fg", "kicking points"
          ]

          STAT_TERMS = [
              "Rushing Yards", "Rush Yards", "Rushing Attempts", "Rush Attempts",
              "Receiving Yards", "Receptions", "Longest Reception", "Longest Rush",
              "Passing Yards", "Pass Attempts", "Completions", "Interceptions", "Pass TDs",
              "Fantasy Points", "Tackles + Assists", "Solo Tackles", "Sacks",
              "Field Goals Made",
              "1H Receptions","1H Rec Yards","1Q Receptions","1Q Rec Yards",
              "Rush + Rec TDs","1H Rush + Rec TDs","1Q Rush + Rec TDs"
          ]

          def looks_nfl_stat(stat_key: str) -> bool:
              s = as_str(stat_key).lower()
              return any(k in s for k in NFL_STAT_HINTS)

          def split_title(title: str):
              t = as_str(title)
              for term in sorted(STAT_TERMS, key=len, reverse=True):
                  if term in t:
                      name = t.split(term)[0].strip()
                      return name, term
              m = re.match(r"^([A-Za-z .'\-]+?)\s+(.*)$", t)
              if m:
                  return m.group(1).strip(), m.group(2).strip()
              return "", ""

          def harvest_items(blob):
              if isinstance(blob, dict):
                  for k in ("over_under_lines","offers","data","items"):
                      if isinstance(blob.get(k), list):
                          for it in blob[k]:
                              yield it
              elif isinstance(blob, list):
                  for it in blob:
                      yield it

          rows = []
          json_files = sorted(glob.glob(os.path.join(RAW_DIR, "raw_over_under_lines_*.json")))
          json_files += sorted(glob.glob(os.path.join(RAW_DIR, "raw_over_under_lines_v2_*.json")))
          json_files += sorted(glob.glob(os.path.join(RAW_DIR, "raw_offers_*.json")))

          for jf in json_files:
              try:
                  with open(jf, "r", encoding="utf-8") as f:
                      data = json.load(f)
              except Exception:
                  continue

              for it in harvest_items(data):
                  ou = it.get("over_under", {}) if isinstance(it, dict) else {}
                  title = as_str(ou.get("title"))
                  stat_key = as_str(ou.get("appearance_stat", {}).get("stat") or ou.get("stat"))
                  line = it.get("stat_value") or it.get("non_discounted_stat_value")
                  updated = as_str(it.get("updated_at") or it.get("modified_at") or it.get("created_at"))

                  player, market = split_title(title)
                  if not (player and market):
                      continue

                  if not looks_nfl_stat(stat_key):
                      continue

                  for opt in (it.get("options") or []):
                      side_raw = as_str(opt.get("type"))
                      side = {"higher":"Over","over":"Over","lower":"Under","under":"Under"}.get(side_raw.lower(), side_raw.title())
                      try:
                          line_num = float(line)
                      except Exception:
                          line_num = line
                      rows.append({
                          "player": player,
                          "market": market,
                          "stat_key": stat_key.lower(),
                          "line": line_num,
                          "side": side,
                          "updated_at": updated
                      })

          df = pd.DataFrame(rows, columns=["player","market","stat_key","line","side","updated_at"]).drop_duplicates()

          if not df.empty:
              df["_key"] = (
                  df["player"].str.lower().str.strip() + "|" +
                  df["market"].str.lower().str.strip() + "|" +
                  df["stat_key"].str.lower().str.strip() + "|" +
                  df["line"].astype(str) + "|" +
                  df["side"].str.lower().str.strip()
              )
              df = df.sort_values("updated_at", ascending=False).drop_duplicates("_key").drop(columns=["_key"])

          df.to_csv(OUT_CSV, index=False)
          print("NFL ROWS:", len(df))
          print(df.head(20).to_string(index=False))

          if len(df) == 0:
              raise SystemExit("No NFL props parsed from raw payloads. Check raw JSON structure and filters.")
          PY

      - name: Sanity check rowcount
        run: |
          python - << 'PY'
          import pandas as pd
          df = pd.read_csv("underdog_nfl_props.csv")
          n = len(df)
          print("Rows:", n)
          # Adjust threshold as you like for game days
          if n < 100:
              raise SystemExit(f"Rowcount too low ({n}) — investigate filters or endpoint shape.")
          PY

      - name: Upload outputs
        uses: actions/upload-artifact@v4
        with:
          name: underdog_nfl_dump
          path: |
            underdog_nfl_props.csv
            raw_payloads/**
